{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21cf2336-f5b7-409c-b553-8a6eef0620bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2016 Election \"What-If\" Simulator- Notebook\n",
    "## Electoral College Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62a18dd7-e774-4922-a0cf-d9431512b55c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SETUP & DATA LOADING\n",
    "#### Cell 1: Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e25cadb-f3fb-4d5e-8584-17e14ee4e445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(\"workspace.default.1976_2020_president\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cf0655b-9b18-41a8-86c0-75519370ed5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 2: Create Bronze Table (Raw Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3110489-bebc-4fe0-8a40-6e5f6d836619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"elections_bronze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54a30d08-d2b9-4ced-9b67-19b7a65bcd76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 3: Explore Bronze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af5f70e8-c327-41c2-b73b-ea0bd9db2e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the bronze table\n",
    "bronze_df = spark.table(\"elections_bronze\")\n",
    "\n",
    "# Check what columns you have\n",
    "print(bronze_df.columns)\n",
    "bronze_df.select(\"year\", \"state\", \"party_simplified\", \"candidate\", \"candidatevotes\", \"totalvotes\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "605eebcb-9988-40a8-9149-5645a2a1d423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 4: Clean & Transform (Silver Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0feabe3-6b5e-4f96-95bc-c3ea81ae8677",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, first\n",
    "\n",
    "# Clean and aggregate to state level\n",
    "silver_df = bronze_df.filter(col(\"candidatevotes\").isNotNull()) \\\n",
    "    .groupBy(\"year\", \"state\", \"party_simplified\", \"candidate\") \\\n",
    "    .agg(\n",
    "        sum(\"candidatevotes\").alias(\"total_votes\"),\n",
    "        first(\"totalvotes\").alias(\"state_total_votes\")\n",
    "    ) \\\n",
    "    .withColumn(\"vote_share\", col(\"total_votes\") / col(\"state_total_votes\"))\n",
    "\n",
    "silver_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dda1e9d0-486c-424a-a8c2-beb26f9c39a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 5: Save Silver Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af01a819-683b-414f-9dc8-c0b736c179be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"elections_silver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e92138d-f75f-481a-82d2-e723be316f68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 6: Filter to 2016 Election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2811adbd-780a-4e75-9583-4c38967b64e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Election to simulate: 2016\n",
    "base_election = spark.table(\"elections_silver\").filter(col(\"year\") == 2016)\n",
    "base_election.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8010be34-9bcf-4966-b616-e8647724f45a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### ELECTORAL COLLEGE SIMULATION\n",
    "#### Cell 7: Electoral College Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abdbccff-8a45-469a-acdd-ae81c0c399be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Map states to electoral votes (2016 counts)\n",
    "electoral_votes = {\n",
    "    'ALABAMA': 9, 'ALASKA': 3, 'ARIZONA': 11, 'ARKANSAS': 6,\n",
    "    'CALIFORNIA': 55, 'COLORADO': 9, 'CONNECTICUT': 7, 'DELAWARE': 3,\n",
    "    'DISTRICT OF COLUMBIA': 3, 'FLORIDA': 29, 'GEORGIA': 16, 'HAWAII': 4,\n",
    "    'IDAHO': 4, 'ILLINOIS': 20, 'INDIANA': 11, 'IOWA': 6,\n",
    "    'KANSAS': 6, 'KENTUCKY': 8, 'LOUISIANA': 8, 'MAINE': 4,\n",
    "    'MARYLAND': 10, 'MASSACHUSETTS': 11, 'MICHIGAN': 16, 'MINNESOTA': 10,\n",
    "    'MISSISSIPPI': 6, 'MISSOURI': 10, 'MONTANA': 3, 'NEBRASKA': 5,\n",
    "    'NEVADA': 6, 'NEW HAMPSHIRE': 4, 'NEW JERSEY': 14, 'NEW MEXICO': 5,\n",
    "    'NEW YORK': 29, 'NORTH CAROLINA': 15, 'NORTH DAKOTA': 3, 'OHIO': 18,\n",
    "    'OKLAHOMA': 7, 'OREGON': 7, 'PENNSYLVANIA': 20, 'RHODE ISLAND': 4,\n",
    "    'SOUTH CAROLINA': 9, 'SOUTH DAKOTA': 3, 'TENNESSEE': 11, 'TEXAS': 38,\n",
    "    'UTAH': 6, 'VERMONT': 3, 'VIRGINIA': 13, 'WASHINGTON': 12,\n",
    "    'WEST VIRGINIA': 5, 'WISCONSIN': 10, 'WYOMING': 3\n",
    "}\n",
    "\n",
    "# Use Python's builtin sum, not PySpark's sum\n",
    "total_ev = 0\n",
    "for ev in electoral_votes.values():\n",
    "    total_ev += ev\n",
    "print(f\"Total Electoral Votes: {total_ev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d941e5d-02b0-4a5b-8d6e-0133bbb3d470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 8: Electoral College Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "408fefc3-bdb4-4e9a-90c4-33bec9419233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand, when, lit, sum, col\n",
    "import random\n",
    "\n",
    "def simulate_election_ec(base_df, swing_states, flip_probability, electoral_map):\n",
    "    \"\"\"\n",
    "    Simulate election using Electoral College\n",
    "    Randomly flips swing states and calculates electoral votes\n",
    "    \"\"\"\n",
    "    result_df = base_df.withColumn(\"adjusted_votes\", col(\"total_votes\"))\n",
    "    \n",
    "    # Track which states flipped\n",
    "    flipped_states = []\n",
    "    \n",
    "    # Flip each swing state randomly\n",
    "    for state in swing_states:\n",
    "        if random.random() < flip_probability:\n",
    "            flipped_states.append(state)\n",
    "            \n",
    "            # Get top 2 candidates in this state\n",
    "            state_results = result_df.filter(col(\"state\") == state) \\\n",
    "                .filter(col(\"party_simplified\").isin([\"DEMOCRAT\", \"REPUBLICAN\"])) \\\n",
    "                .orderBy(col(\"total_votes\").desc()) \\\n",
    "                .limit(2) \\\n",
    "                .collect()\n",
    "        \n",
    "            if len(state_results) >= 2:\n",
    "                winner_candidate = state_results[0][\"candidate\"]\n",
    "                second_candidate = state_results[1][\"candidate\"]\n",
    "                winner_votes = state_results[0][\"total_votes\"]\n",
    "                second_votes = state_results[1][\"total_votes\"]\n",
    "\n",
    "                # Swap the votes between top 2 candidates\n",
    "                result_df = result_df.withColumn(\n",
    "                    \"adjusted_votes\",\n",
    "                    when(\n",
    "                        (col(\"state\") == state) & (col(\"candidate\") == winner_candidate),\n",
    "                        lit(second_votes)\n",
    "                    ).when(\n",
    "                        (col(\"state\") == state) & (col(\"candidate\") == second_candidate),\n",
    "                        lit(winner_votes)\n",
    "                    ).otherwise(col(\"adjusted_votes\"))\n",
    "                )\n",
    "    \n",
    "    # Calculate electoral votes for each candidate\n",
    "    # Find winner in each state\n",
    "    state_winners = result_df.filter(col(\"party_simplified\").isin([\"DEMOCRAT\", \"REPUBLICAN\"])) \\\n",
    "        .groupBy(\"state\", \"candidate\") \\\n",
    "        .agg(sum(\"adjusted_votes\").alias(\"state_total\")) \\\n",
    "        .orderBy(\"state\", col(\"state_total\").desc())\n",
    "    \n",
    "    # Get top candidate per state\n",
    "    from pyspark.sql.window import Window\n",
    "    from pyspark.sql.functions import row_number\n",
    "    \n",
    "    window_spec = Window.partitionBy(\"state\").orderBy(col(\"state_total\").desc())\n",
    "    state_winners = state_winners.withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "        .filter(col(\"rank\") == 1) \\\n",
    "        .drop(\"rank\")\n",
    "    \n",
    "    # Calculate electoral votes\n",
    "    ec_results = {}\n",
    "    for row in state_winners.collect():\n",
    "        state = row[\"state\"]\n",
    "        candidate = row[\"candidate\"]\n",
    "        ev = electoral_map.get(state, 0)\n",
    "        \n",
    "        if candidate not in ec_results:\n",
    "            ec_results[candidate] = 0\n",
    "        ec_results[candidate] += ev\n",
    "    \n",
    "    # Find winner (270 to win)\n",
    "    winner = max(ec_results.items(), key=lambda x: x[1])\n",
    "    \n",
    "    return {\n",
    "        'candidate': winner[0],\n",
    "        'electoral_votes': winner[1],\n",
    "        'flipped_states': flipped_states,\n",
    "        'all_results': ec_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28c1636e-198c-44fa-ae41-f283e9b2defd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 9: Test Simulation Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10711ac7-3f9e-498a-8e47-b71c0fb7584c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test it once\n",
    "swing_states = [\"FLORIDA\", \"PENNSYLVANIA\", \"MICHIGAN\", \"WISCONSIN\"]\n",
    "result = simulate_election_ec(base_election, swing_states, 0.5, electoral_votes)\n",
    "\n",
    "print(f\"Winner: {result['candidate']}\")\n",
    "print(f\"Electoral Votes: {result['electoral_votes']}\")\n",
    "print(f\"Flipped States: {result['flipped_states']}\")\n",
    "print(f\"All Results: {result['all_results']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a456bccc-2c12-4ede-9285-650d9395213a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### RUN SIMULATIONS\n",
    "#### Cell 10: Run 1000 Simulations (Base Scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8525be65-d396-47d0-8d9e-81a203444b93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run 100 simulations\n",
    "swing_states = [\"FLORIDA\", \"PENNSYLVANIA\", \"MICHIGAN\", \"WISCONSIN\"]\n",
    "results = []\n",
    "\n",
    "for i in range(1000):\n",
    "    result = simulate_election_ec(base_election, swing_states, flip_probability=0.5, electoral_map=electoral_votes)\n",
    "    results.append((\n",
    "        i, \n",
    "        result['candidate'], \n",
    "        result['electoral_votes'],\n",
    "        len(result['flipped_states']),\n",
    "        str(result['flipped_states'])\n",
    "    ))\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = spark.createDataFrame(\n",
    "    results, \n",
    "    [\"sim_id\", \"winner\", \"electoral_votes\", \"num_flips\", \"flipped_states\"]\n",
    ")\n",
    "\n",
    "results_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"simulation_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f4a881f-eb1d-47be-9a56-0c5e703d10f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 11: Analyze Base Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "933d3657-e79d-41d9-bada-5db323bbf227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, avg\n",
    "\n",
    "# Count wins per candidate\n",
    "win_counts = spark.table(\"simulation_results\") \\\n",
    "    .groupBy(\"winner\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"wins\"),\n",
    "        (count(\"*\") / 1000 * 100).alias(\"win_probability\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"wins\").desc())\n",
    "\n",
    "win_counts.show()\n",
    "\n",
    "# Average electoral votes\n",
    "avg_ev = spark.table(\"simulation_results\") \\\n",
    "    .groupBy(\"winner\") \\\n",
    "    .agg(avg(\"electoral_votes\").alias(\"avg_electoral_votes\"))\n",
    "\n",
    "avg_ev.show()\n",
    "\n",
    "# Save as gold table\n",
    "win_counts.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"elections_gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a4b6b99-8b6f-46dd-b65d-9b3bcfe36aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 12: Aggressive Scenario (80% flip probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "895088f4-220e-4e4d-85cf-9ede95f49c9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Scenario 1: Higher flip probability\n",
    "results_aggressive = []\n",
    "\n",
    "for i in range(1000):\n",
    "    result = simulate_election_ec(base_election, swing_states, flip_probability=0.8, electoral_map=electoral_votes)\n",
    "    results_aggressive.append((\n",
    "        i, \n",
    "        result['candidate'], \n",
    "        result['electoral_votes']\n",
    "    ))\n",
    "\n",
    "results_aggressive_df = spark.createDataFrame(\n",
    "    results_aggressive, \n",
    "    [\"sim_id\", \"winner\", \"electoral_votes\"]\n",
    ")\n",
    "\n",
    "results_aggressive_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"simulation_aggressive\")\n",
    "\n",
    "# Check results\n",
    "spark.table(\"simulation_aggressive\") \\\n",
    "    .groupBy(\"winner\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"wins\"),\n",
    "        (count(\"*\") / 1000 * 100).alias(\"win_probability\")\n",
    "    ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbf8aef5-8586-4192-ab45-8958e5c3df71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 13: More Swings States Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "446a77b7-ea43-47c1-9345-a48b0518865f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Scenario 2: Add more swing states\n",
    "more_swing_states = [\"FLORIDA\", \"PENNSYLVANIA\", \"MICHIGAN\", \"WISCONSIN\", \n",
    "                     \"ARIZONA\", \"GEORGIA\", \"NORTH CAROLINA\", \"NEVADA\"]\n",
    "\n",
    "results_more_states = []\n",
    "\n",
    "for i in range(1000):\n",
    "    result = simulate_election_ec(base_election, more_swing_states, flip_probability=0.5, electoral_map=electoral_votes)\n",
    "    results_more_states.append((\n",
    "        i, \n",
    "        result['candidate'], \n",
    "        result['electoral_votes']\n",
    "    ))\n",
    "\n",
    "results_more_df = spark.createDataFrame(\n",
    "    results_more_states, \n",
    "    [\"sim_id\", \"winner\", \"electoral_votes\"]\n",
    ")\n",
    "\n",
    "results_more_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"simulation_more_states\")\n",
    "\n",
    "# Check results\n",
    "spark.table(\"simulation_more_states\") \\\n",
    "    .groupBy(\"winner\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"wins\"),\n",
    "        (count(\"*\") / 1000 * 100).alias(\"win_probability\")\n",
    "    ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c0b6154-2913-4686-b47c-4288013019d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### VISUALIZATION\n",
    "#### Cell 14: Compare All Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b89c71e-b054-4459-9850-7e21153671b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Get results from all three scenarios\n",
    "base_wins = spark.table(\"simulation_results\").groupBy(\"winner\").count().toPandas()\n",
    "base_wins['scenario'] = 'Base (50% flip, 4 states)'\n",
    "\n",
    "aggressive_wins = spark.table(\"simulation_aggressive\").groupBy(\"winner\").count().toPandas()\n",
    "aggressive_wins['scenario'] = 'Aggressive (80% flip, 4 states)'\n",
    "\n",
    "more_states_wins = spark.table(\"simulation_more_states\").groupBy(\"winner\").count().toPandas()\n",
    "more_states_wins['scenario'] = 'More States (50% flip, 8 states)'\n",
    "\n",
    "# Combine\n",
    "all_results = pd.concat([base_wins, aggressive_wins, more_states_wins])\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "all_results_pivot = all_results.pivot(index='scenario', columns='winner', values='count').fillna(0)\n",
    "all_results_pivot.plot(kind='bar', ax=ax, width=0.8)\n",
    "\n",
    "plt.title('Election Outcomes Across Different Scenarios (100 simulations each)', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Number of Wins', fontsize=12)\n",
    "plt.xlabel('Scenario', fontsize=12)\n",
    "plt.legend(title='Winner', fontsize=10)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b425cda2-9c48-4fce-b4bf-7d1d6b87dd16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Cell 15: Electoral Vote Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "996e95ee-c5d1-4f23-b6b1-706adfc96c01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show distribution of electoral votes for each winner\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Base scenario\n",
    "base_ev = spark.table(\"simulation_results\").toPandas()\n",
    "for winner in base_ev['winner'].unique():\n",
    "    winner_data = base_ev[base_ev['winner'] == winner]['electoral_votes']\n",
    "    axes[0].hist(winner_data, bins=20, alpha=0.7, label=winner)\n",
    "axes[0].set_title('Base Scenario')\n",
    "axes[0].set_xlabel('Electoral Votes')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "axes[0].axvline(270, color='red', linestyle='--', label='270 to win')\n",
    "\n",
    "# Aggressive scenario\n",
    "agg_ev = spark.table(\"simulation_aggressive\").toPandas()\n",
    "for winner in agg_ev['winner'].unique():\n",
    "    winner_data = agg_ev[agg_ev['winner'] == winner]['electoral_votes']\n",
    "    axes[1].hist(winner_data, bins=20, alpha=0.7, label=winner)\n",
    "axes[1].set_title('Aggressive Scenario')\n",
    "axes[1].set_xlabel('Electoral Votes')\n",
    "axes[1].legend()\n",
    "axes[1].axvline(270, color='red', linestyle='--')\n",
    "\n",
    "# More states scenario\n",
    "more_ev = spark.table(\"simulation_more_states\").toPandas()\n",
    "for winner in more_ev['winner'].unique():\n",
    "    winner_data = more_ev[more_ev['winner'] == winner]['electoral_votes']\n",
    "    axes[2].hist(winner_data, bins=20, alpha=0.7, label=winner)\n",
    "axes[2].set_title('More States Scenario')\n",
    "axes[2].set_xlabel('Electoral Votes')\n",
    "axes[2].legend()\n",
    "axes[2].axvline(270, color='red', linestyle='--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fee08c9-82d9-4bba-bbb1-6e0d93e13bfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SUMMARY REPORT\n",
    "#### Cell 16: Generate Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1bd0627-440c-4e74-93d2-d80a0f45b00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, avg, min, max\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"2016 ELECTION 'WHAT-IF' SIMULATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Scenario 1: Base\n",
    "print(\"SCENARIO 1: Base Case (4 swing states, 50% flip probability)\")\n",
    "print(\"-\" * 80)\n",
    "base_summary = spark.table(\"simulation_results\").groupBy(\"winner\").agg(\n",
    "    count(\"*\").alias(\"wins\"),\n",
    "    avg(\"electoral_votes\").alias(\"avg_ev\"),\n",
    "    min(\"electoral_votes\").alias(\"min_ev\"),\n",
    "    max(\"electoral_votes\").alias(\"max_ev\")\n",
    ").toPandas()\n",
    "print(base_summary.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Scenario 2: Aggressive\n",
    "print(\"SCENARIO 2: Aggressive (4 swing states, 80% flip probability)\")\n",
    "print(\"-\" * 80)\n",
    "agg_summary = spark.table(\"simulation_aggressive\").groupBy(\"winner\").agg(\n",
    "    count(\"*\").alias(\"wins\"),\n",
    "    avg(\"electoral_votes\").alias(\"avg_ev\"),\n",
    "    min(\"electoral_votes\").alias(\"min_ev\"),\n",
    "    max(\"electoral_votes\").alias(\"max_ev\")\n",
    ").toPandas()\n",
    "print(agg_summary.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Scenario 3: More states\n",
    "print(\"SCENARIO 3: More Swing States (8 swing states, 50% flip probability)\")\n",
    "print(\"-\" * 80)\n",
    "more_summary = spark.table(\"simulation_more_states\").groupBy(\"winner\").agg(\n",
    "    count(\"*\").alias(\"wins\"),\n",
    "    avg(\"electoral_votes\").alias(\"avg_ev\"),\n",
    "    min(\"electoral_votes\").alias(\"min_ev\"),\n",
    "    max(\"electoral_votes\").alias(\"max_ev\")\n",
    ").toPandas()\n",
    "print(more_summary.to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Presidential Elections",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
